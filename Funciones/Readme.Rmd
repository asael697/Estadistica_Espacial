---
title: "Prueba_Metropolis"
author: "Asael"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(
  collapse = TRUE, fig.path = "Figures/", dev = "png")
```

```{r,message=FALSE}
source("functions.R")

library(posterior)
library(bayesplot)
library(ggplot2)
library(loo)
```

## Pruebas para validar los MCMC en distribuciones univariadas

Este cuaderno hace un prueba de la funcionalidad del algortimo de Metropolis implementado en el archivo `functions.R`, en este experimento se simularan datos de una normal univariada mediante las siguientes ecuaciones

$$
y = \mu + \sigma \varepsilon, \quad \varepsilon \sim N(0,1),\\
\mu \sim N(0,1), \quad \sigma \sim logN(1,1).
$$

Los datos se simulan mediante el siguiente codigo:

```{r}
#priors
mu = rnorm(1)
sigma = rlnorm(1,meanlog = 1)
# datos
y = rnorm(n = 100,mean = mu,sd = sigma)

ggplot(data.frame(y),aes(x = y))+geom_histogram(bins = 20)+
  labs(x = "y",y = "conteo",title = "Histograma de los datos simulados y")
```

Ahora bien, previo a la estimacion de los parametros, actualizamos las funciones `loglik()`, `log_prior()` y `inits()` para que calculen la verosimilitud, el logaritmo de la prior y valores iniciales, de forma correcta. Estas funciones son necesarias para el salto de metropolis (`metropolis_step`) y para la iniciacion correcta del algoritmo (`metropolis_sampler()`). 


```{r}
# Estimacion de la log-verosimilitud
loglik <- function(y,theta){
    z = y - 5
    d = sum(dnorm(x = y,mean = 0,sd = theta[1],log = TRUE))
    d = ifelse(is.na(d),-10^(64),d)
   return(sum(d))
}

# Calculo de la log prior logP(theta)
log_prior <- function(theta){
  d1 = dnorm(theta[1],log = TRUE)
  return(d1)
}

# Generacion de los valores iniciales
inits <- function(y,d = 2){
  c(rlnorm(1,meanlog = 1))
}
```

Ahora bien, procedemos a generar nuestras cadenas de Markov usando el algoritmo de Metropolis. En este caso la funcion de salto es una normal multivariada simetrica $proposed \sim N_2(prop,diag(1,1))$, con matriz de covarianza siendo la matriz identidad. Se generaron 4 cadenas de Markov de un total de 10,000 iteraciones por cadena (`iter = 10,000`), donde se eliminaron las primeras 2,000 iteraciones (`burn-in = 2500`), y se acortaron las cadenas con un `thinning` de cada 5 saltos (`thin = 5`) para evitar que las cadenas se quedaran estancadas.

```{r,warning=FALSE}
scale_mat  = diag(c(1,1))

start = Sys.time()
post1 = sampling(y,iter = 5000, scale = scale_mat, thin = 3)
print( Sys.time() - start)
```

Los resultados obtenidos muestran convergencia en las cadenas $\hat R \approx 1$, pero los tamaños de muestra efectivos son lo muy bajos, como para aceptar las simulaciones obtenidas. Notemos que las posteriors si recuperaron los valores reales de $\mu$ (`r mu`) y $\sigma$ (`r sigma`), pero dada su poca convergencia no quantifican bien la incertidumbre de los parametros.

```{r}
colnames(post1) = c("mu","sigma","accpetence_rate",".chain")
post_df = as_draws_df(post1)

summarise_draws(post_df)
```

La siguiente visualización muestra las posterios y cadenas para ambos parametros, los cadenas quedan en puntos de acumulacion debido al bajo ratio de rechazo y las posteriors son deformes, indicando que es necesario realizar mas iteraciones. 

```{r}
color_scheme_set("mix-gray-brightblue")
mcmc_combo(post_df,pars = c("mu","sigma"))
```

## Adjusted scale metropolis

Una alternativa a aumentar el numero de iteraciones es controlar el factor de escala de la cadena, para eso haremos un algoritmo de Metropolis-Hastings con factor de escala ajustado, en este caso la distribution de salto es:

$$x_k = x_{k-1} + \sqrt h \Sigma^{1./2} \varepsilon, \quad \varepsilon \sim N_d(0,I).$$
Donde $h$ es el factor de escala que corrige la matriz de covarianza $\Sigma$, y d es la dimension de los parametros a obtener ($x$). Un mejor control de $h$ aumentaria la tasa de aceptacion del MCMC. para este caso elegimos $h = 0.01$ y reducimos el acortamiento a 1

```{r,warning=FALSE}
scale_mat  = diag(c(1,1))

start = Sys.time()
post1 = sampling(y,iter = 5000, scale = scale_mat, thin = 1, h = 0.1)
print( Sys.time() - start)
```

El tiempo de ejecucion se ve reducido, ademas que la convergencia y tamaño de las cadenas es mejor con respecto al tiempo anterior, y la tasa de acceptacion incremento.

```{r}
colnames(post1) = c("mu","sigma","accpetence_rate",".chain")
post_df = as_draws_df(post1)

summarise_draws(post_df)
```

La siguiente visualización muestra las posterios y cadenas para ambos parametros, las cadenas se visualizan estacionaria y  las posteriors menos deformes, indicando convergencia. 

```{r}
color_scheme_set("viridisC")
mcmc_combo(post_df,pars = c("mu","sigma"))
```


Para una mayor tasa de rechazo se puede incrementar el tamanio de muesta, mejorar el factor de escala, o intentar un MCMC adaptativo.

## Pruebas para validar el filtro de Kalman hacia adelante

Para validar el algoritmo se simula una serie de tiempo multivariada de dimension $m = 2$ y tamaño $n = 250$ observaciones. Los parámetros latentes $\mu_t \in \mathbb R^3$, Usando un DLM constante. En este caso, las matrices $G, FF, V$ y $W$ se simulan aleatoriamente, y los parametros latentes iniciales son: 

$$m_0 = [0,0,0] \quad u \quad C_0 = 100*diag(1,1,1).$$
Dicha serie de tiempo se simula mediante el siguiente codigo

```{r}
library(dlm)

rm = dlmRandom(m = 2,p = 3,nobs = 250)
```

Los parametros simulados del DLM constante son

```{r}
list(FF = rm$mod$FF, G = rm$mod$GG, V = rm$mod$V, W = rm$mod$W)
```

Ajustamos el filtro de Kalman hacia delante con nuestra implementación y la realizada por el paquete `DLM`. Comparamos los resultados de $m_t$ y $C_t$ obtenidos, con la norma 2 para el vector de medias y la norma 1 para las matrices de covarianza.

```{r}
# Nuestra implementacion 
kf1 = forward_filter(y = rm$y, G = rm$mod$GG, FF = t(rm$mod$FF),
               V = rm$mod$V, W = rm$mod$W, m0 = rm$mod$m0,
               C0 = rm$mod$C0)

# Implementacion paquete DLM
filt1 = dlmFilter(y = rm$y,mod = rm$mod)
```


$$e_{mt} = || our - dlm||_2$$
```{r}
e_mt = kf1$mt - filt1$m
apply(e_mt,2,function(x) sqrt(sum(x^2)) )
```

y

$$e_{Ct} = || OUR - DLM||_1$$

```{r}
e_Ct = rep(0,250)

for (i in 1:250) {
  C_temp = filt1$U.C[[i]] %*% diag(filt1$D.C[i,]^2) %*% t(filt1$U.C[[i]])
  e_Ct[i] = norm(kf1$Ct[[i]] - C_temp,type = "1")
}

summary(e_Ct)
```


Observamos que todos los errores son aproximadamente cero y por lo tanto validamos nuestra implementacion del Filtro de Kalman hacia adelante.
